\mu=1  with linear search



Step[1]:  x=[ 8.000000 90.000000 ] optim_fx=-984.155200
Step[2]:  x=[ 6.255004 92.932310 ] optim_fx=-996.693602
Step[3]:  x=[ 2.082236 97.829863 ] optim_fx=-1004.905759
Step[4]:  x=[ 0.905083 99.001762 ] optim_fx=-1005.283151
Step[5]:  x=[ 0.971637 98.928978 ] optim_fx=-1005.288312
Step[6]:  x=[ 0.976890 98.923281 ] optim_fx=-1005.288337
Step[7]:  x=[ 0.976918 98.923250 ] optim_fx=-1005.288337

牛顿Armijo回溯法,,共迭代 7 步
结果：
  x=[ 9.769181e-01 9.892325e+01 ] optim_fx=-1005.288337



Step[1]:  x=[ 1.000000 40.000000 ] optim_fx=-421.255053
Step[2]:  x=[ 1.032871 77.681054 ] optim_fx=-798.390805
Step[3]:  x=[ 1.037574 93.676328 ] optim_fx=-957.303576
Step[4]:  x=[ 1.037526 97.948101 ] optim_fx=-998.444109
Step[5]:  x=[ 1.033614 98.532714 ] optim_fx=-1003.411469
Step[6]:  x=[ 1.018676 98.910198 ] optim_fx=-1005.235957
Step[7]:  x=[ 0.975135 98.933287 ] optim_fx=-1005.284716
Step[8]:  x=[ 0.976915 98.923936 ] optim_fx=-1005.288313
Step[9]:  x=[ 0.976918 98.923255 ] optim_fx=-1005.288337
Step[10]:  x=[ 0.976918 98.923250 ] optim_fx=-1005.288337

牛顿Armijo回溯法,,共迭代 10 步
结果：
  x=[ 9.769181e-01 9.892325e+01 ] optim_fx=-1005.288337






Step[1]:  x=[ 15.000000 68.690000 ] optim_fx=-836.270838
Step[2]:  x=[ 15.006566 78.259960 ] optim_fx=-931.363936
Step[3]:  x=[ 13.698221 83.008948 ] optim_fx=-966.383156
Step[4]:  x=[ 8.670766 91.305575 ] optim_fx=-998.910392
Step[5]:  x=[ 0.329966 99.644118 ] optim_fx=-1004.256876
Step[6]:  x=[ 0.548496 99.406399 ] optim_fx=-1004.903321
Step[7]:  x=[ 0.789054 99.141115 ] optim_fx=-1005.210170
Step[8]:  x=[ 0.940799 98.968385 ] optim_fx=-1005.283294
Step[9]:  x=[ 0.975583 98.925399 ] optim_fx=-1005.288302
Step[10]:  x=[ 0.976916 98.923259 ] optim_fx=-1005.288337
Step[11]:  x=[ 0.976918 98.923250 ] optim_fx=-1005.288337

牛顿Armijo回溯法,,共迭代 11 步
结果：
  x=[ 9.769181e-01 9.892325e+01 ] optim_fx=-1005.288337



Step[1]:  x=[ 10.000000 20.000000 ] optim_fx=-303.641157
Step[2]:  x=[ 23.891723 73.017999 ] optim_fx=-958.394392
Step[3]:  x=[ 11.153740 88.595405 ] optim_fx=-996.698346
Step[4]:  x=[ 4.190159 95.582603 ] optim_fx=-1002.999973
Step[5]:  x=[ 0.759243 99.085990 ] optim_fx=-1005.147228
Step[6]:  x=[ 0.928428 99.001969 ] optim_fx=-1005.229181
Step[7]:  x=[ 0.974513 98.934808 ] optim_fx=-1005.283855
Step[8]:  x=[ 0.976912 98.924095 ] optim_fx=-1005.288301
Step[9]:  x=[ 0.976918 98.923257 ] optim_fx=-1005.288337
Step[10]:  x=[ 0.976918 98.923250 ] optim_fx=-1005.288337

牛顿Armijo回溯法,,共迭代 10 步
结果：
  x=[ 9.769181e-01 9.892325e+01 ] optim_fx=-1005.288337






